{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naar: https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deze cel hoeft alleen als MacOS klaagt over Certificates\n",
    "# hieronder bij het downloaden van de dataset maar kan\n",
    "# anders vast ook geen kwaad... ;-)\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "    getattr(ssl, '_create_unverified_context', None)): \n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download en lees de dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print de klasselabels\n",
    "twenty_train.target_names #prints all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "# Hoeveel trainingsinstances zijn er?\n",
    "print(len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: ktj@beach.cis.ufl.edu (kerry todd johnson)\n",
      "Subject: army in space\n",
      "Organization: Univ. of Florida CIS Dept.\n",
      "Lines: 17\n",
      "Distribution: world\n",
      "NNTP-Posting-Host: beach.cis.ufl.edu\n",
      "\n",
      "\n",
      "Is anybody out there willing to discuss with me careers in the Army that deal\n",
      "with space?  After I graduate, I will have a commitment to serve in the Army, \n",
      "and I would like to spend it in a space-related field.  I saw a post a long\n",
      "time ago about the Air Force Space Command which made a fleeting reference to\n",
      "its Army counter-part.  Any more info on that would be appreciated.  I'm \n",
      "looking for things like: do I branch Intelligence, or Signal, or other?  To\n",
      "whom do I voice my interest in space?  What qualifications are necessary?\n",
      "Etc, etc.  BTW, my major is computer science engineering.\n",
      "\n",
      "Please reply to ktj@reef.cis.ufl.edu\n",
      "\n",
      "Thanks for ANY info.\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Whether they ever find life there or not, I think Jupiter should be         =\n",
      "= considered an enemy planet.  --  Jack Handy                                 =\n",
      "---ktj@reef.cis.ufl.edu---cirop59@elm.circa.ufl.edu---endeavour@circa.ufl.edu--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a random instance\n",
    "from random import randint\n",
    "print(twenty_train.data[randint(0, len(twenty_train.data)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bepaal welke woorden hoe vaak voorkomen in elke instance\n",
    "# Dit heet het \"Bag of Words\" model\n",
    "# Negeert de niet-betekenisvolle \"stopwoorden\" en zeldzame\n",
    "# woorden\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english', max_features=10000, max_df=0.9)\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Word Stemming/Lemmatization wordt ook gedaan, betreft het samenvoegen van verschillende uitgangen (bv. meervouden, werkwoordsvervoegingen, e.d.), maar doe ik even niet omdat dit over EN tekst gaat en wij NL gaan doen.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of beter, zet aantallen om in frequenties\n",
    "# Term Frequency times Inverse Document Frequency\n",
    "# deelt aantallen zowel door totale aantal per\n",
    "# instance en door log-totale aantal per woord\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train bv. NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8086829527349974"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dit kan ook in één keer met een pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "text_nb = Pipeline([('vect', CountVectorizer(stop_words='english', max_features=10000, max_df=0.9)),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('nb', MultinomialNB()),\n",
    "])\n",
    "text_nb = text_nb.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_nb = text_nb.predict(twenty_test.data)\n",
    "np.mean(predicted_nb == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8271375464684015"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Idem met Support Vector Machine\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_svm = Pipeline([('vect', CountVectorizer(stop_words='english', max_features=10000, max_df=0.9)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('svm', SGDClassifier()),\n",
    "])\n",
    "text_svm.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_svm = text_svm.predict(twenty_test.data)\n",
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierna kijken naar Word Embeddings i.p.v. Bag of Words. Zie bv.:\n",
    "\n",
    "* https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\n",
    "\n",
    "* https://realpython.com/python-keras-text-classification/\n",
    "\n",
    "* https://medium.com/analytics-vidhya/text-classification-using-word-embeddings-and-deep-learning-in-python-classifying-tweets-from-6fe644fcfc81\n",
    "\n",
    "* https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
